# -*- coding: utf-8 -*-
"""model_mnist_dataset_softmax.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CG8lA5UvVdw5YecIb8wmBYHb-DOxsMDB
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow as tf

from tensorflow.examples.tutorials.mnist import input_data    # Imports mnist tutorial libraries used by tutorial examples.

mnist= input_data.read_data_sets("MNIST_data/",one_hot=True)  # Function for downloading and reading MNIST data.
                                                              # one_hot=True ensures that the labels are one_hot coded

type(mnist)

mnist.train.images

mnist.train.num_examples

mnist.test.num_examples

mnist.validation.num_examples

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

mnist.train.images.shape          # 55000 samples each of 784 (=28*28) pixels

single_image = mnist.train.images[1].reshape(28,28)    # single_image is a 2d array with values b/w 0 and 1, both inclusive.

plt.imshow(single_image,cmap='gist_gray')           # cmap='gist_gray' makes the img black and white with gist of gray

single_image.min()

single_image.max()

single_image



# USING SOFTMAX REGRESSION APPROACH

# placeholders
x=tf.placeholder(tf.float32,shape=[None,784])

# variables
w=tf.Variable(tf.zeros([784,10]))            # weights
b=tf.Variable(tf.zeros([10]))                # bias
#Note:- having weights as zero initially is not good in real case scenario. Here it is taken 0 just for simplifiation
        # the weights and bias gets updated in every iteration and finally reaching the best value.



# graph operation
y=tf.matmul(x,w)+b



# loss function
y_true= tf.placeholder(tf.float32,shape=[None,10])
cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y))



# optimizer
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)
train=optimizer.minimize(cross_entropy)



# create session
init= tf.global_variables_initializer()

saver = tf.train.Saver()

import time
start = time.time()
with tf.Session() as sess:
    sess.run(init)
    
    for steps in range(1000):
        batch_x,batch_y = mnist.train.next_batch(100)
        
        sess.run(train,feed_dict={x:batch_x,y_true:batch_y})
                        # first argument is the optimizer function. The second is the data which we want to feed
                        # Since the data is trained here, so both x and y are training data here.
        
        
    # evaluation of model
    correct_prediction=  tf.equal(tf.argmax(y,1), tf.argmax(y_true,1)) 
                                        # argmax() will return list of the index position of the label with highest probablity
                                        # actually it returns the index with the largest value across axes of a tensor
                                        # meaning to say that it will tell what label it thinks it is
                                        # the second argument is the axis
            
    # correct_prediction is a list of trues and false. We need to convert it to zeros and ones to further do calculations
    cast_prediction= tf.cast(correct_prediction,tf.float32)
     
    accuracy=tf.reduce_mean(cast_prediction)    
    
    print(sess.run(accuracy,feed_dict={x:mnist.test.images,y_true:mnist.test.labels}))
                        # Since the data is tested here, so both x and y are testing data here.

    saver.save(sess,'model_char_recog.ckpt')
end = time.time()

