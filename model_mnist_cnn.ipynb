{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "model_mnist_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVHebi6mdKDp",
        "colab_type": "code",
        "outputId": "0d6ce775-0926-4b66-fcdd-ebf94311c958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import time\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GvOPBTwdKD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4VJZA1QdKEP",
        "colab_type": "code",
        "outputId": "6b40d436-a0af-4ee0-dfb5-d77199940649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "mnist= input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-71d5fea259fa>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7XvW7jadKEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGkDxUTPdKEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some helper functions:-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKfY9SD_dKE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) initializing weights\n",
        "def init_weights(shape):\n",
        "    init_random_dist=tf.truncated_normal(shape,stddev=0.1)\n",
        "    \"\"\"Outputs random values from a truncated normal distribution.\n",
        "    The generated values follow a normal distribution with specified mean and standard deviation, \n",
        "    except that values whose magnitude is more than 2 standard deviations from the mean are dropped \n",
        "    and re-picked.\"\"\"\n",
        "    \"\"\"Normal distribution, also known as the Gaussian distribution, is a probability distribution that is \n",
        "    symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far \n",
        "    from the mean. In graph form, normal distribution will appear as a bell curve.\"\"\"\n",
        "    return tf.Variable(init_random_dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z9aQOUTdKFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) initializing bias\n",
        "def init_bias(shape):\n",
        "    init_bias_vals=tf.constant(0.1,shape=shape)          # all values are 0.1 and the shape is that of the tensor\n",
        "    return tf.Variable(init_bias_vals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmzqAmlVdKFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3) convolutional func\n",
        "def conv2d(x,W):\n",
        "    # x is the input tensor.A 4d tensor. its shape:- [batch,height,width,channel]  (channel is 1 for grayscale and 3 for rgb)\n",
        "    # batch basically tells which all images are being taken as i/p/. height and weight are of individual images. \n",
        "    # W is the kernel(or the filter).its shape:- [filter height,filter width,no. of channels as i/p, no. of channels as o/p ]\n",
        "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')    \n",
        "                        # basic 2d convolutional function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAXEjJkEdKFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4) pooling\n",
        "def max_pool_2by2(x):\n",
        "    # x is the input tensor. its shape:- [batch,height,width,channel] \n",
        "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "                # pooling is done only along height and width. so, it is basically 2*2 pooling\n",
        "                # ksize specifies the size of the window for each dimension of input tensor\n",
        "                # stride specifies the stride of the sliding window for each dimension of input tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPBbB6v6dKF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfuSjpVAdKGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convolutional layer\n",
        "def convolutional_layer(input_x,shape):\n",
        "    w=init_weights(shape)\n",
        "    b=init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x,w)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mA2T_xpdKGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal (or, fully connected) layer\n",
        "def normal_full_layer(input_layer,size):\n",
        "    input_size=int(input_layer.get_shape()[1])\n",
        "    w=init_weights([input_size,size])\n",
        "    b=init_bias([size])\n",
        "    return tf.matmul(input_layer,w)+b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lidEL_JYdKHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWi3XjKidKHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# placeholder\n",
        "x=tf.placeholder(tf.float32,shape=[None,784])\n",
        "y_true=tf.placeholder(tf.float32,shape=[None,10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sfSnOytdKHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzCBJO8kdKH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# layers\n",
        "x_image= tf.reshape(x,[-1,28,28,1])   # converting the i/p img back to layers. The 28*28 is h*w. 1 is coz of grayscale."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g99uLONYdKIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first convolutional layer\n",
        "convo_1=convolutional_layer(x_image,shape=[5,5,1,32]) # the wt. tensor is [5,5,1,32]\n",
        "                                                      # 5 by 5 convolutional layer. so, this convolution will compute\n",
        "                                                      # 32 features for each 5 by 5 patch. 1 is the i/p channels.32 is the no.\n",
        "                                                      # of o/p channels."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L7QH5uPdKIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first pooling layer\n",
        "convo_1_pooling = max_pool_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcegUtMbdKI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second convolutional layer\n",
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[5,5,32,64])    # 64 features\n",
        "convo_2_pooling= max_pool_2by2(convo_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MZ9Ie85dKJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this o/p is now flattened out so that it gets connected to a fully connected layer\n",
        "convo_2_flat= tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
        "#here 7*7 is dimension of each image. here's how:-\n",
        "#28*28 on pooling with 2*2 gives 14*14\n",
        "#14*14 on pooling with 2*2 gives 7*7\n",
        "#NOTE:- the dimension of the image didn't change on convolution as \"SAME\" type of convolution is used.Meaning to say that the padding is such that the final\n",
        "#       o/p dimension remains the same.here, padding=(f-1)/2=(5-1)/2=2 . so after padding , 28*28 becomes 32*32. and on convolution gives 28*28 \n",
        "#       (as, n-f+1=32-5+1=28  )\n",
        "full_layer_one=tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3yN5SacdKJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ7GmuZvdKJ1",
        "colab_type": "code",
        "outputId": "0565066b-d685-424b-dff5-f1c6707b2134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# dropout\n",
        "hold_prob= tf.placeholder(tf.float32)\n",
        "full_one_dropout= tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-17-62245365a1b4>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIIX9RRkdKKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred= normal_full_layer(full_one_dropout,10)    # 10 is the no. of labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk60kitgdKKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJbml2FUdKKn",
        "colab_type": "code",
        "outputId": "96396d78-24de-46cd-e9d7-a924b725c64b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# loss function\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-e0c07892321c>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5wnU8hedKK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "train =  optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GydzzF4jdKLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init= tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYR0inU8d-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47bSMA2ldKLW",
        "colab_type": "code",
        "outputId": "1bd42d07-d40c-484e-8429-3a486b448d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = time.time()\n",
        "steps=5000\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        batch_x,batch_y= mnist.train.next_batch(50)\n",
        "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})   \n",
        "                                    # hold_prob:0.5 implies every neuron has a 50% hold probablity\n",
        "        if(i%100==0):\n",
        "            print(\"On Step: {}\".format(i))\n",
        "            print(\"Accuracy:  \")\n",
        "            matches=tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "            #argmax(input, axis=None, name=None, dimension=None) Returns the index with the largest value across axis of a tensor\n",
        "            \n",
        "            acc=tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "            print(sess.run(acc,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
        "            # during testing we don't want to dropout any of the neurons. So, we write hold_prob:1.0 , meaning that every neuron will be held at its \n",
        "            # position and none will be dropped out\n",
        "            print('\\n')\n",
        "\n",
        "            saver.save(sess,'model_char_recog.ckpt')\n",
        "end = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Step: 0\n",
            "Accuracy:  \n",
            "0.1294\n",
            "\n",
            "\n",
            "On Step: 100\n",
            "Accuracy:  \n",
            "0.9433\n",
            "\n",
            "\n",
            "On Step: 200\n",
            "Accuracy:  \n",
            "0.96\n",
            "\n",
            "\n",
            "On Step: 300\n",
            "Accuracy:  \n",
            "0.971\n",
            "\n",
            "\n",
            "On Step: 400\n",
            "Accuracy:  \n",
            "0.9724\n",
            "\n",
            "\n",
            "On Step: 500\n",
            "Accuracy:  \n",
            "0.9785\n",
            "\n",
            "\n",
            "On Step: 600\n",
            "Accuracy:  \n",
            "0.982\n",
            "\n",
            "\n",
            "On Step: 700\n",
            "Accuracy:  \n",
            "0.9836\n",
            "\n",
            "\n",
            "On Step: 800\n",
            "Accuracy:  \n",
            "0.9803\n",
            "\n",
            "\n",
            "On Step: 900\n",
            "Accuracy:  \n",
            "0.9837\n",
            "\n",
            "\n",
            "On Step: 1000\n",
            "Accuracy:  \n",
            "0.9823\n",
            "\n",
            "\n",
            "On Step: 1100\n",
            "Accuracy:  \n",
            "0.9861\n",
            "\n",
            "\n",
            "On Step: 1200\n",
            "Accuracy:  \n",
            "0.9858\n",
            "\n",
            "\n",
            "On Step: 1300\n",
            "Accuracy:  \n",
            "0.9859\n",
            "\n",
            "\n",
            "On Step: 1400\n",
            "Accuracy:  \n",
            "0.9848\n",
            "\n",
            "\n",
            "On Step: 1500\n",
            "Accuracy:  \n",
            "0.9885\n",
            "\n",
            "\n",
            "On Step: 1600\n",
            "Accuracy:  \n",
            "0.9894\n",
            "\n",
            "\n",
            "On Step: 1700\n",
            "Accuracy:  \n",
            "0.9848\n",
            "\n",
            "\n",
            "On Step: 1800\n",
            "Accuracy:  \n",
            "0.9862\n",
            "\n",
            "\n",
            "On Step: 1900\n",
            "Accuracy:  \n",
            "0.9893\n",
            "\n",
            "\n",
            "On Step: 2000\n",
            "Accuracy:  \n",
            "0.988\n",
            "\n",
            "\n",
            "On Step: 2100\n",
            "Accuracy:  \n",
            "0.9883\n",
            "\n",
            "\n",
            "On Step: 2200\n",
            "Accuracy:  \n",
            "0.9886\n",
            "\n",
            "\n",
            "On Step: 2300\n",
            "Accuracy:  \n",
            "0.9863\n",
            "\n",
            "\n",
            "On Step: 2400\n",
            "Accuracy:  \n",
            "0.9898\n",
            "\n",
            "\n",
            "On Step: 2500\n",
            "Accuracy:  \n",
            "0.9887\n",
            "\n",
            "\n",
            "On Step: 2600\n",
            "Accuracy:  \n",
            "0.9895\n",
            "\n",
            "\n",
            "On Step: 2700\n",
            "Accuracy:  \n",
            "0.9885\n",
            "\n",
            "\n",
            "On Step: 2800\n",
            "Accuracy:  \n",
            "0.99\n",
            "\n",
            "\n",
            "On Step: 2900\n",
            "Accuracy:  \n",
            "0.9896\n",
            "\n",
            "\n",
            "On Step: 3000\n",
            "Accuracy:  \n",
            "0.9888\n",
            "\n",
            "\n",
            "On Step: 3100\n",
            "Accuracy:  \n",
            "0.9904\n",
            "\n",
            "\n",
            "On Step: 3200\n",
            "Accuracy:  \n",
            "0.9867\n",
            "\n",
            "\n",
            "On Step: 3300\n",
            "Accuracy:  \n",
            "0.9898\n",
            "\n",
            "\n",
            "On Step: 3400\n",
            "Accuracy:  \n",
            "0.9875\n",
            "\n",
            "\n",
            "On Step: 3500\n",
            "Accuracy:  \n",
            "0.9903\n",
            "\n",
            "\n",
            "On Step: 3600\n",
            "Accuracy:  \n",
            "0.9902\n",
            "\n",
            "\n",
            "On Step: 3700\n",
            "Accuracy:  \n",
            "0.9896\n",
            "\n",
            "\n",
            "On Step: 3800\n",
            "Accuracy:  \n",
            "0.9909\n",
            "\n",
            "\n",
            "On Step: 3900\n",
            "Accuracy:  \n",
            "0.9892\n",
            "\n",
            "\n",
            "On Step: 4000\n",
            "Accuracy:  \n",
            "0.9882\n",
            "\n",
            "\n",
            "On Step: 4100\n",
            "Accuracy:  \n",
            "0.9894\n",
            "\n",
            "\n",
            "On Step: 4200\n",
            "Accuracy:  \n",
            "0.9907\n",
            "\n",
            "\n",
            "On Step: 4300\n",
            "Accuracy:  \n",
            "0.9905\n",
            "\n",
            "\n",
            "On Step: 4400\n",
            "Accuracy:  \n",
            "0.9882\n",
            "\n",
            "\n",
            "On Step: 4500\n",
            "Accuracy:  \n",
            "0.9884\n",
            "\n",
            "\n",
            "On Step: 4600\n",
            "Accuracy:  \n",
            "0.9906\n",
            "\n",
            "\n",
            "On Step: 4700\n",
            "Accuracy:  \n",
            "0.9911\n",
            "\n",
            "\n",
            "On Step: 4800\n",
            "Accuracy:  \n",
            "0.9909\n",
            "\n",
            "\n",
            "On Step: 4900\n",
            "Accuracy:  \n",
            "0.9883\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS2ExGA1dKLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tdLS0J9prFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting on single examples\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikx1tyqAp73G",
        "colab_type": "code",
        "outputId": "4989f995-768a-4fba-d8db-f90d11a83a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "image_index = 4444\n",
        "single_image = mnist.train.images[image_index].reshape(28,28) \n",
        "plt.imshow(single_image,cmap='gist_gray') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f990485d2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNSYcVxj8wXt",
        "colab_type": "code",
        "outputId": "430d9216-f8c8-4745-ea40-ecb6fb180366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  saver.restore(sess, \"model_char_recog.ckpt\")\n",
        "       \n",
        "  single_image = mnist.train.images[image_index]     \n",
        "  prediction=tf.argmax(y_pred,1)\n",
        "  var = prediction.eval(feed_dict={x: [single_image],y_true:mnist.train.labels,hold_prob: 1.0}, session=sess)\n",
        "  print(\"The predicted character is :- \" + str(var))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_char_recog.ckpt\n",
            "The predicted character is :- [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo8E-SJqBgJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ks1uSb0G4Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}