{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "char_recognition_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjTWfiK5jVrRUZLRKMbztw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzfy6lqOIDYq",
        "colab_type": "code",
        "outputId": "84ca2cb1-9c03-4394-e2c4-a9063e74e4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaT18m5UPL5v",
        "colab_type": "code",
        "outputId": "66b822ae-a015-4905-cb03-bbe3ddc78d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG-U3FEVlpP0",
        "colab_type": "code",
        "outputId": "683aa641-141d-4343-80aa-97e31828f53f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5hHaqcSl3L0",
        "colab_type": "code",
        "outputId": "04ae4d9e-6828-455e-b1c7-0fa000d52096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#pip install python-mnist"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-mnist\n",
            "  Downloading https://files.pythonhosted.org/packages/64/f0/6086b84427c3bf156ec0b3c2f9dfc1d770b35f942b9ed8a64f5229776a80/python_mnist-0.7-py2.py3-none-any.whl\n",
            "Installing collected packages: python-mnist\n",
            "Successfully installed python-mnist-0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZDdbI1fl7x3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mnist import MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2JWC-WjmJuJ",
        "colab_type": "code",
        "outputId": "3fd56ccf-4e0a-4e55-881b-4b7a25f20e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ls emnist_data/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emnist-balanced-test-images-idx3-ubyte.gz\n",
            "emnist-balanced-test-labels-idx1-ubyte.gz\n",
            "emnist-balanced-train-images-idx3-ubyte.gz\n",
            "emnist-balanced-train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joh7aTJSmPR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emnist = MNIST('emnist_data/')\n",
        "emnist.select_emnist('balanced')\n",
        "\n",
        "images,labels = emnist.load_training()\n",
        "testIM,testLAB = emnist.load_testing()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFv6znisuKdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxxuNObeu1pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_images = np.array(images)   \n",
        "n_labels = np.array(labels)   \n",
        "test_images = np.array(testIM)   \n",
        "testLAB = np.array(testLAB) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkSKtHGy6vjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fitting data b/w 0 and 1 (for easy calculation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGmknv2k6793",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()                                #this makes scaler_model (a variable) an instance of  MinMaxScaler\n",
        "scaler.fit(n_images)                                   #this fits the data in the model\n",
        "train_images = scaler.transform(n_images)              #finally this converts the data between the given range.By default, 0 to 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCHvOPSQ7Af6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler.fit(testIM)\n",
        "test_images = scaler.transform(testIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh8iuAX77BH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz6I4kMw7Bt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encoding of labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W_T15oUwaNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "shaped_n_labels  = n_labels.reshape(-1,1)\n",
        "enc = OneHotEncoder()\n",
        "enc.fit(shaped_n_labels)\n",
        "train_labels = enc.transform(shaped_n_labels).toarray()\n",
        "\n",
        "shaped_testLAB = testLAB.reshape(-1,1)\n",
        "enc.fit(shaped_testLAB)\n",
        "test_labels = enc.transform(shaped_testLAB).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1scNurg0xRea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#naming the labels\n",
        "labels_dict ={0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9,10:'A',11:'B',12:'C',13:'D',14:'E',\n",
        "              15:'F',16:'G',17:'H',18:'I',19:'J',20:'K',21:'l',22:'M',23:'N',24:'O',25:'P',\n",
        "              26:'Q',27:'R',28:'S',29:'T',30:'u',31:'V',32:'W',33:'X',34:'Y',35:'Z',36:'a',\n",
        "              37:'b',38:'d',39:'e',40:'f',41:'g',42:'h',43:'n',44:'q',45:'r',46:'t'}\n",
        "\n",
        "# the following characters are left out due to similarity in their upper case and lower case representations (or similarity with other characters)\n",
        "# L, U, c,i,j,k,m,o,p,s,v,w,x,y,z  (total 15)\n",
        "#so, characters [a-z] , [A-Z], [0-9] are total 26+26+10=62\n",
        "#15 are not used. So, remaining no. of labels =62-15=47"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apQ_ZCWRWTYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWMmUcub8Ywp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some helper functions:-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pZ5F538xlMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1) initializing weights\n",
        "def init_weights(shape):\n",
        "    init_random_dist=tf.truncated_normal(shape,stddev=0.1)\n",
        "    \"\"\"Outputs random values from a truncated normal distribution.\n",
        "    The generated values follow a normal distribution with specified mean and standard deviation, \n",
        "    except that values whose magnitude is more than 2 standard deviations from the mean are dropped \n",
        "    and re-picked.\"\"\"\n",
        "    \"\"\"Normal distribution, also known as the Gaussian distribution, is a probability distribution that is \n",
        "    symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far \n",
        "    from the mean. In graph form, normal distribution will appear as a bell curve.\"\"\"\n",
        "    return tf.Variable(init_random_dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJOtToSwxm5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2) initializing bias\n",
        "def init_bias(shape):\n",
        "    init_bias_vals=tf.constant(0.1,shape=shape)          # all values are 0.1 and the shape is that of the tensor\n",
        "    return tf.Variable(init_bias_vals)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byac-RaKxqcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3) convolutional func\n",
        "def conv2d(x,W):\n",
        "    # x is the input tensor.A 4d tensor. its shape:- [batch,height,width,channel]  (channel is 1 for grayscale and 3 for rgb)\n",
        "    # batch basically tells which all images are being taken as i/p/. height and weight are of individual images. \n",
        "    # W is the kernel(or the filter).its shape:- [filter height,filter width,no. of channels as i/p, no. of channels as o/p ]\n",
        "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')    \n",
        "                        # basic 2d convolutional function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhfb6uSPxs9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4) pooling\n",
        "def max_pool_2by2(x):\n",
        "    # x is the input tensor. its shape:- [batch,height,width,channel] \n",
        "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "                # pooling is done only along height and width. so, it is basically 2*2 pooling\n",
        "                # ksize specifies the size of the window for each dimension of input tensor\n",
        "                # stride specifies the stride of the sliding window for each dimension of input tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8aHjL2xuxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ylS6QcVxwCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convolutional layer\n",
        "def convolutional_layer(input_x,shape):\n",
        "    w=init_weights(shape)\n",
        "    b=init_bias([shape[3]])\n",
        "    return tf.nn.relu(conv2d(input_x,w)+b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQLQ_YmLxyLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal (or, fully connected) layer\n",
        "def normal_full_layer(input_layer,size):\n",
        "    input_size=int(input_layer.get_shape()[1])\n",
        "    w=init_weights([input_size,size])\n",
        "    b=init_bias([size])\n",
        "    return tf.matmul(input_layer,w)+b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JpPG0wjxzkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaslO9hYx1Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# placeholder\n",
        "x=tf.placeholder(tf.float32,shape=[None,784])\n",
        "y_true=tf.placeholder(tf.float32,shape=[None,47])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-X8ioVPx1_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH8HmNiJyLuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# layers\n",
        "x_image= tf.reshape(x,[-1,28,28,1])   # converting the i/p img back to layers. The 28*28 is h*w. 1 is coz of grayscale."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buW-rMWdx3Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first convolutional layer\n",
        "convo_1=convolutional_layer(x_image,shape=[5,5,1,32]) # the wt. tensor is [5,5,1,32]\n",
        "                                                      # 5 by 5 convolutional layer. so, this convolution will compute\n",
        "                                                      # 32 features for each 5 by 5 patch. 1 is the i/p channels.32 is the no.\n",
        "                                                      # of o/p channels."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdFogeY4x5IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first pooling layer\n",
        "convo_1_pooling = max_pool_2by2(convo_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiI3l3GWyRDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# second convolutional layer\n",
        "convo_2 = convolutional_layer(convo_1_pooling,shape=[5,5,32,64])    # 64 features\n",
        "convo_2_pooling= max_pool_2by2(convo_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOImGl3hvYkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh3ww5nBySv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this o/p is now flattened out so that it gets connected to a fully connected layer\n",
        "convo_2_flat= tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
        "#here 7*7 is dimension of each image. here's how:-\n",
        "#28*28 on pooling with 2*2 gives 14*14\n",
        "#14*14 on pooling with 2*2 gives 7*7\n",
        "#NOTE:- the dimension of the image didn't change on convolution as \"SAME\" type of convolution is used.Meaning to say that the padding is such that the final\n",
        "#       o/p dimension remains the same.here, padding=(f-1)/2=(5-1)/2=2 . so after padding , 28*28 becomes 32*32. and on convolution gives 28*28 \n",
        "#       (as, n-f+1=32-5+1=28  )\n",
        "full_layer_one=tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1rKhykRNwX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlrmpzuMu0as",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuKuysJ6u6Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVM5nu8lyU-e",
        "colab_type": "code",
        "outputId": "77489f79-81d2-46fa-bb2e-f0c2e531fc97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# dropout\n",
        "hold_prob= tf.placeholder(tf.float32)\n",
        "full_one_dropout= tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-62245365a1b4>:2: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjBtgpxxyXnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYT-trNDyaRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred= normal_full_layer(full_one_dropout,47)    # 47 is the no. of labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyf7W1AVzp7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYMPNDZPzt0b",
        "colab_type": "code",
        "outputId": "47ae324f-17aa-412a-8645-892529b68a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# loss function\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-e0c07892321c>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B6YvLmYzuih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n",
        "train =  optimizer.minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUFuGXG0zw1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init= tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPePx_C9zyn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saver = tf.train.Saver()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT8pL8c1z0ZK",
        "colab_type": "code",
        "outputId": "490acfd9-b85e-4400-9f51-300af9b87a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = time.time()\n",
        "steps=6000\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    \n",
        "    for i in range(steps):\n",
        "        #batch_x,batch_y= train_images.next_batch(50)\n",
        "        rand_idx=np.random.randint(0,112800,90)\n",
        "        batch_x= train_images[rand_idx]\n",
        "        batch_y=train_labels[rand_idx]\n",
        "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})   \n",
        "                                    # hold_prob:0.5 implies every neuron has a 50% hold probablity\n",
        "        if(i%100==0):\n",
        "            print(\"On Step: {}\".format(i))\n",
        "            print(\"Accuracy:  \")\n",
        "            matches=tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "            #argmax(input, axis=None, name=None, dimension=None) Returns the index with the largest value across axis of a tensor\n",
        "            \n",
        "            acc=tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "            print(sess.run(acc,feed_dict={x:test_images,y_true:test_labels,hold_prob:1.0}))\n",
        "            # during testing we don't want to dropout any of the neurons. So, we write hold_prob:1.0 , meaning that every neuron will be held at its \n",
        "            # position and none will be dropped out\n",
        "            print('\\n')\n",
        "\n",
        "            saver.save(sess,'model_char_recog.ckpt')\n",
        "end = time.time()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On Step: 0\n",
            "Accuracy:  \n",
            "0.019627659\n",
            "\n",
            "\n",
            "On Step: 100\n",
            "Accuracy:  \n",
            "0.59590423\n",
            "\n",
            "\n",
            "On Step: 200\n",
            "Accuracy:  \n",
            "0.7154787\n",
            "\n",
            "\n",
            "On Step: 300\n",
            "Accuracy:  \n",
            "0.74787235\n",
            "\n",
            "\n",
            "On Step: 400\n",
            "Accuracy:  \n",
            "0.7831383\n",
            "\n",
            "\n",
            "On Step: 500\n",
            "Accuracy:  \n",
            "0.80281913\n",
            "\n",
            "\n",
            "On Step: 600\n",
            "Accuracy:  \n",
            "0.8089362\n",
            "\n",
            "\n",
            "On Step: 700\n",
            "Accuracy:  \n",
            "0.8161702\n",
            "\n",
            "\n",
            "On Step: 800\n",
            "Accuracy:  \n",
            "0.8249468\n",
            "\n",
            "\n",
            "On Step: 900\n",
            "Accuracy:  \n",
            "0.83292556\n",
            "\n",
            "\n",
            "On Step: 1000\n",
            "Accuracy:  \n",
            "0.8323404\n",
            "\n",
            "\n",
            "On Step: 1100\n",
            "Accuracy:  \n",
            "0.8324468\n",
            "\n",
            "\n",
            "On Step: 1200\n",
            "Accuracy:  \n",
            "0.83904254\n",
            "\n",
            "\n",
            "On Step: 1300\n",
            "Accuracy:  \n",
            "0.8431383\n",
            "\n",
            "\n",
            "On Step: 1400\n",
            "Accuracy:  \n",
            "0.8423404\n",
            "\n",
            "\n",
            "On Step: 1500\n",
            "Accuracy:  \n",
            "0.84760636\n",
            "\n",
            "\n",
            "On Step: 1600\n",
            "Accuracy:  \n",
            "0.8498404\n",
            "\n",
            "\n",
            "On Step: 1700\n",
            "Accuracy:  \n",
            "0.85218084\n",
            "\n",
            "\n",
            "On Step: 1800\n",
            "Accuracy:  \n",
            "0.8567553\n",
            "\n",
            "\n",
            "On Step: 1900\n",
            "Accuracy:  \n",
            "0.85457444\n",
            "\n",
            "\n",
            "On Step: 2000\n",
            "Accuracy:  \n",
            "0.85781914\n",
            "\n",
            "\n",
            "On Step: 2100\n",
            "Accuracy:  \n",
            "0.8580319\n",
            "\n",
            "\n",
            "On Step: 2200\n",
            "Accuracy:  \n",
            "0.85867023\n",
            "\n",
            "\n",
            "On Step: 2300\n",
            "Accuracy:  \n",
            "0.85712767\n",
            "\n",
            "\n",
            "On Step: 2400\n",
            "Accuracy:  \n",
            "0.85877657\n",
            "\n",
            "\n",
            "On Step: 2500\n",
            "Accuracy:  \n",
            "0.85952127\n",
            "\n",
            "\n",
            "On Step: 2600\n",
            "Accuracy:  \n",
            "0.8600532\n",
            "\n",
            "\n",
            "On Step: 2700\n",
            "Accuracy:  \n",
            "0.8622872\n",
            "\n",
            "\n",
            "On Step: 2800\n",
            "Accuracy:  \n",
            "0.8634043\n",
            "\n",
            "\n",
            "On Step: 2900\n",
            "Accuracy:  \n",
            "0.8667553\n",
            "\n",
            "\n",
            "On Step: 3000\n",
            "Accuracy:  \n",
            "0.8662234\n",
            "\n",
            "\n",
            "On Step: 3100\n",
            "Accuracy:  \n",
            "0.8669681\n",
            "\n",
            "\n",
            "On Step: 3200\n",
            "Accuracy:  \n",
            "0.8695745\n",
            "\n",
            "\n",
            "On Step: 3300\n",
            "Accuracy:  \n",
            "0.86994684\n",
            "\n",
            "\n",
            "On Step: 3400\n",
            "Accuracy:  \n",
            "0.8718085\n",
            "\n",
            "\n",
            "On Step: 3500\n",
            "Accuracy:  \n",
            "0.8698936\n",
            "\n",
            "\n",
            "On Step: 3600\n",
            "Accuracy:  \n",
            "0.868617\n",
            "\n",
            "\n",
            "On Step: 3700\n",
            "Accuracy:  \n",
            "0.8692553\n",
            "\n",
            "\n",
            "On Step: 3800\n",
            "Accuracy:  \n",
            "0.8707447\n",
            "\n",
            "\n",
            "On Step: 3900\n",
            "Accuracy:  \n",
            "0.87037235\n",
            "\n",
            "\n",
            "On Step: 4000\n",
            "Accuracy:  \n",
            "0.8690426\n",
            "\n",
            "\n",
            "On Step: 4100\n",
            "Accuracy:  \n",
            "0.8687234\n",
            "\n",
            "\n",
            "On Step: 4200\n",
            "Accuracy:  \n",
            "0.8717553\n",
            "\n",
            "\n",
            "On Step: 4300\n",
            "Accuracy:  \n",
            "0.8712234\n",
            "\n",
            "\n",
            "On Step: 4400\n",
            "Accuracy:  \n",
            "0.8696808\n",
            "\n",
            "\n",
            "On Step: 4500\n",
            "Accuracy:  \n",
            "0.87148935\n",
            "\n",
            "\n",
            "On Step: 4600\n",
            "Accuracy:  \n",
            "0.87090427\n",
            "\n",
            "\n",
            "On Step: 4700\n",
            "Accuracy:  \n",
            "0.8737766\n",
            "\n",
            "\n",
            "On Step: 4800\n",
            "Accuracy:  \n",
            "0.87026596\n",
            "\n",
            "\n",
            "On Step: 4900\n",
            "Accuracy:  \n",
            "0.8720745\n",
            "\n",
            "\n",
            "On Step: 5000\n",
            "Accuracy:  \n",
            "0.8745745\n",
            "\n",
            "\n",
            "On Step: 5100\n",
            "Accuracy:  \n",
            "0.8739362\n",
            "\n",
            "\n",
            "On Step: 5200\n",
            "Accuracy:  \n",
            "0.87329787\n",
            "\n",
            "\n",
            "On Step: 5300\n",
            "Accuracy:  \n",
            "0.87755316\n",
            "\n",
            "\n",
            "On Step: 5400\n",
            "Accuracy:  \n",
            "0.87234044\n",
            "\n",
            "\n",
            "On Step: 5500\n",
            "Accuracy:  \n",
            "0.87654257\n",
            "\n",
            "\n",
            "On Step: 5600\n",
            "Accuracy:  \n",
            "0.87914896\n",
            "\n",
            "\n",
            "On Step: 5700\n",
            "Accuracy:  \n",
            "0.8739362\n",
            "\n",
            "\n",
            "On Step: 5800\n",
            "Accuracy:  \n",
            "0.8764362\n",
            "\n",
            "\n",
            "On Step: 5900\n",
            "Accuracy:  \n",
            "0.878883\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG6KovDUCs_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting on single examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSqP2kPsTncQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYGu4El6H3XX",
        "colab_type": "code",
        "outputId": "d6499a84-a16f-47bf-c643-8bb0053ae18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "image_index = 444\n",
        "single_image = train_images[image_index].reshape(28,28) \n",
        "plt.imshow(single_image,cmap='gist_gray') "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c846f4908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQHBe-2SS9h_",
        "colab_type": "code",
        "outputId": "ea9c948b-1eaa-4859-9002-b4c1008e5b85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  saver.restore(sess, \"model_char_recog.ckpt\")\n",
        "       \n",
        "  single_image = train_images[image_index]     \n",
        "  prediction=tf.argmax(y_pred,1)\n",
        "  var = prediction.eval(feed_dict={x: [single_image],y_true:train_labels,hold_prob: 1.0}, session=sess)\n",
        "  print(\"The predicted character is :- \" + str(labels_dict[var[0]]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_char_recog.ckpt\n",
            "The predicted character is :- E\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkuJsfXsTVbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxLmwHHmdeNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predicting on images given by user"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeDNFSE7tim8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to convert user image into image suitable for the dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCNr038Tt0i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image, ImageFilter\n",
        "\n",
        "\n",
        "def imageprepare(argv):\n",
        "    \"\"\"\n",
        "    This function returns the pixel values.\n",
        "    The imput is a png file location.\n",
        "    \"\"\"\n",
        "    im = Image.open(argv).convert('L')\n",
        "    width = float(im.size[0])\n",
        "    height = float(im.size[1])\n",
        "    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels\n",
        "\n",
        "    if width > height:  # check which dimension is bigger\n",
        "        # Width is bigger. Width becomes 20 pixels.\n",
        "        nheight = int(round((28.0 / width * height), 0))  # resize height according to ratio width\n",
        "        if (nheight == 0):  # rare case but minimum is 1 pixel\n",
        "            nheight = 1\n",
        "            # resize and sharpen\n",
        "        img = im.resize((28, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
        "        wtop = int(round(((28 - nheight) / 2), 0))  # calculate horizontal position\n",
        "        newImage.paste(img, (0, wtop))  # paste resized image on white canvas\n",
        "    else:\n",
        "        # Height is bigger. Heigth becomes 20 pixels.\n",
        "        nwidth = int(round((28.0 / height * width), 0))  # resize width according to ratio height\n",
        "        if (nwidth == 0):  # rare case but minimum is 1 pixel\n",
        "            nwidth = 1\n",
        "            # resize and sharpen\n",
        "        img = im.resize((nwidth, 28), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)\n",
        "        wleft = int(round(((28 - nwidth) / 2), 0))  # caculate vertical pozition\n",
        "        newImage.paste(img, (wleft, 0))  # paste resized image on white canvas\n",
        "\n",
        "    # newImage.save(\"sample.png\n",
        "\n",
        "    tv = list(newImage.getdata())  # get pixel values\n",
        "\n",
        "    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
        "    tva = [(255 - x) * 1.0 / 255.0 for x in tv]\n",
        "    #print(tva)\n",
        "    for i in range(len(tva)):\n",
        "        if tva[i]<=0.45:\n",
        "            tva[i]=0.0\n",
        "    return tva"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fflZ9K_aOs9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_img=imageprepare('./P.jpg')#file path here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNUk7FLUMvJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_img=np.array(my_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipc57HBOM8Vi",
        "colab_type": "code",
        "outputId": "57c70eca-1497-4957-dcd8-15063bd47a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.imshow(my_img.reshape(28,28),cmap='gist_gray') "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c85451710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2VyvW_fuFYf",
        "colab_type": "code",
        "outputId": "602473f5-2541-448d-8eb0-3378e8e6c2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  saver.restore(sess, \"model_char_recog.ckpt\")\n",
        "     \n",
        "  prediction=tf.argmax(y_pred,1)\n",
        "  var = prediction.eval(feed_dict={x: [my_img],y_true:train_labels,hold_prob: 1.0}, session=sess)\n",
        "  print(\"The predicted character is :- \" + str(labels_dict[var[0]]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_char_recog.ckpt\n",
            "The predicted character is :- P\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuhQZhEyppq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZbwyr1KpqPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmCLqpbwpsvw",
        "colab_type": "code",
        "outputId": "1d1a0c0c-68eb-4a12-987d-d4095bd590a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "my_img=imageprepare('./B.jpg')#file path here\n",
        "my_img=np.array(my_img)\n",
        "plt.imshow(my_img.reshape(28,28),cmap='gist_gray') "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c853c2278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hgc4Ojep1d-",
        "colab_type": "code",
        "outputId": "788b51d3-22b2-41c9-d2b3-43c9883d9818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  saver.restore(sess, \"model_char_recog.ckpt\")\n",
        "     \n",
        "  prediction=tf.argmax(y_pred,1)\n",
        "  var = prediction.eval(feed_dict={x: [my_img],y_true:train_labels,hold_prob: 1.0}, session=sess)\n",
        "  print(\"The predicted character is :- \" + str(labels_dict[var[0]]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_char_recog.ckpt\n",
            "The predicted character is :- B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nl7x6Rup6uY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfYaQ7kDqH2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L72qkuPEqJoJ",
        "colab_type": "code",
        "outputId": "b287a3ef-49d5-436c-91ba-6383509f286f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "my_img=imageprepare('./3.jpg')#file path here\n",
        "my_img=np.array(my_img)\n",
        "plt.imshow(my_img.reshape(28,28),cmap='gist_gray') "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c8508c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yui-SZxSqKTS",
        "colab_type": "code",
        "outputId": "b28c3324-8b63-48d6-ca50-d84dd734b6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  saver.restore(sess, \"model_char_recog.ckpt\")\n",
        "     \n",
        "  prediction=tf.argmax(y_pred,1)\n",
        "  var = prediction.eval(feed_dict={x: [my_img],y_true:train_labels,hold_prob: 1.0}, session=sess)\n",
        "  print(\"The predicted character is :- \" + str(labels_dict[var[0]]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_char_recog.ckpt\n",
            "The predicted character is :- J\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kXWlux7qO2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmE0zQDIQZ1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#example 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZWyzQIMNq9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0ca329de-fb74-4929-86b6-03056c6a2068"
      },
      "source": [
        "my_img=imageprepare('./2.jpg')#file path here\n",
        "my_img=np.array(my_img)\n",
        "plt.imshow(my_img.reshape(28,28),cmap='gist_gray') "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7c84ef0160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cymtzWnjQQ0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c41288eb-6151-4e81-89f7-12153da421d9"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  saver.restore(sess, \"model_char_recog.ckpt\")\n",
        "     \n",
        "  prediction=tf.argmax(y_pred,1)\n",
        "  var = prediction.eval(feed_dict={x: [my_img],y_true:train_labels,hold_prob: 1.0}, session=sess)\n",
        "  print(\"The predicted character is :- \" + str(labels_dict[var[0]]))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_char_recog.ckpt\n",
            "The predicted character is :- 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYTFtmKNQdlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}